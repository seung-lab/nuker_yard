[Volumes]
# Voxelwise descriptor volume to segment
#descriptor = gs://microns-seunglab/basil_v0/nucleus/v0_z_intp
#descriptor = gs://microns-seunglab/basil_v0/nucleus/v0_z_intp_intp
#descriptor = gs://microns-seunglab/basil_v0/nucleus/3d_v0
descriptor = gs://neuroglancer/basil_v0/basil_full/nucleus/3d_v1

# Output segmentation
#output = gs://microns-seunglab/basil_v0/nucleus/v0_z_intp/seg
#output = gs://microns-seunglab/basil_v0/nucleus/v0_z_intp_intp/seg
#output = gs://microns-seunglab/basil_v0/nucleus/3d_v0/seg
#output = gs://microns-seunglab/basil_v0/nucleus/3d_v0/seg_again
output = gs://neuroglancer/basil_v0/basil_full/nucleus/3d_v1/seg

# Temporary output for intermediate results
#temp_output = gs://microns-seunglab/basil_v0/nucleus/v0_z_intp/seg_temp
#temp_output = gs://microns-seunglab/basil_v0/nucleus/v0_z_intp_intp/seg_temp
#temp_output = gs://microns-seunglab/basil_v0/nucleus/3d_v0/seg_temp
tempoutput = gs://neuroglancer/basil_v0/basil_full/nucleus/3d_v1/seg_temp


# "Base" segmentation for overlaps and assignment.
#  Likely the morphological segmentation
baseseg = [BASE SEG PATH]

# EM image volume
image = [IMAGE PATH]


[Dimensions]
# Voxel resolution (X, Y, Z)
voxelres = 64, 64, 40

# Lower bound of the bounding box
#startcoord = -192, -192, 0
#0-192_3520-5568_12096-14144.json	
#startcoord = 12096, 3520, 0
startcoord = 832, 320, 0

# Size of the bounding box in each dimension
#vol_shape = 16384, 19456, 1024
#vol_shape = 2048, 2048, 192
volshape = 12288, 16384, 1024
#999 would cause non-alignment error from cloudvolume

# Size of a single chunk in each dimension
#chunkshape = 256, 256, 256
#chunk_shape = 1024, 1024, 1024
#chunk_shape = 1024, 1024, 192
chunkshape = 1024, 1024, 1024
#999 would cause non-alignment error from cloudvolume

# Size of a storage block in cloud storage for 
# the output & tempoutput volumes
blockshape = 128, 128, 64

# Patch size for assignment inference (ignored if not run)
patchshape = 80, 80, 18


[Parameters]
# Connected Components Threshold
ccthresh = 0.5

# Object Size Threshold
szthresh = 1000
 #100

# Dust Threshold
dustthresh = 0

# How much to split up some tasks for merging results across chunks.
# This should be set to 1 for almost all workloads
nummergetasks = 1

# Merging distance for segments assigned to the same partners
# (units should match `voxelres` above)
mergethresh = 0


[Workflow]
# The type of workflow to be run. Determines when some tasks need to happen
# {Segmentation, Segmentation+Assignment}
workflowtype = Segmentation

# The kind of storage backend to use. Database is currently required for
# parallel merging operations
# {Database, File}
workspacetype = File

# URL for accessing the task message queue
queueurl = https://sqs.us-east-1.amazonaws.com/098703261575/shang-generic

# SQL Alchemy connection string, location of a file containing this string,
# or STORAGE_FROM_FILE if using a kubernetes secret.
# This is ignored if workspacetype = File
connectionstr = STORAGE_FROM_FILE

# A directory for storing intermediate data outside of the database.
# This is required for either workspacetype
#storagedir = gs://microns-seunglab/basil_v0/nucleus/v0_z_intp/intermediate
#storagedir = gs://microns-seunglab/basil_v0/nucleus/v0_z_intp_intp/seg_aux
#storagedir = gs://microns-seunglab/basil_v0/nucleus/v0/seg_stitch_aux
# "gs://microns-seunglab/nick/shang-test"
#storagedir = gs://microns-seunglab/basil_v0/nucleus/3d_v0/seg_aux
storagedir = gs://neuroglancer/basil_v0/basil_full/nucleus/3d_v1/seg_aux
